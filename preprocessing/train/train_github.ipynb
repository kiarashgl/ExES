{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n",
    "\n",
    "We should add root directory to path so we can import our model files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../..\")))\n",
    "import importlib\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from model.models import *\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import doc2vec\n",
    "import random\n",
    "from itertools import combinations\n",
    "from random import sample\n",
    "from torch_geometric.utils import dropout_node\n",
    "from github import Repository\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read config YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../github.yaml\"\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['saving_paths']['graph'], 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "with open(config['saving_paths']['all_skills'], 'rb') as f:\n",
    "    all_skills = pickle.load(f)\n",
    "with open(config['saving_paths']['authors_id'], 'rb') as f:\n",
    "    author2id = pickle.load(f)\n",
    "id2author = {v:k for k,v in author2id.items()}\n",
    "\n",
    "\n",
    "with open(\"../../data/github/doc2vec_github.pkl\", 'rb') as f:\n",
    "    doc2vec_model = pickle.load(f)\n",
    "with open(config['repo_dict_path'], \"rb\") as f:\n",
    "    contributors = pickle.load(f)\n",
    "with open(\"../../data/github/good_repos.pkl\", 'rb') as f:\n",
    "    all_repos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tensors from networkx graph of collaboration network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_vec = torch_geometric.utils.from_networkx(graph)\n",
    "graph_x = graph_vec.x.float().to(device)\n",
    "graph_edge_index = graph_vec.edge_index.to(device)\n",
    "\n",
    "# This dict shows the mapping from graph node ids to corresponding indices of the created tensors.\n",
    "mapping = dict(zip(graph.nodes(), range(graph.number_of_nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_repos = []\n",
    "preprocessed_users = {}\n",
    "for i, row in all_repos.iterrows():\n",
    "    conts = []\n",
    "\n",
    "    if row.title not in contributors:\n",
    "        continue\n",
    "\n",
    "    for item in contributors[row.title]['contributors']:\n",
    "        if item.login in author2id:\n",
    "            conts.append(author2id[item.login])\n",
    "    good_repos.append(((i, row.title), row.tags))\n",
    "    \n",
    "    preprocessed_users[i] = conts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization\n",
    "We initialize the model using the model name and parameters that are provided in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['train']['model_name']\n",
    "models_module = importlib.import_module(\"model.models\")\n",
    "model_class = getattr(models_module, model_name)\n",
    "model_parameters = config['train']['model_params']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "\n",
    "model = model_class(*model_parameters)\n",
    "model = model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config['train']['batch_size']\n",
    "num_epochs = config['train']['num_epochs']\n",
    "num_negative_samples = config['train']['num_negative_samples']\n",
    "criterion = torch.nn.CosineEmbeddingLoss(margin=0)\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(range(0, len(good_repos), batch_size)):\n",
    "        optim.zero_grad()\n",
    "        # graph_edge_index, _, _ = dropout_node(graph_edge_index)\n",
    "        emb = model(graph_x, graph_edge_index)\n",
    "\n",
    "        batch_papers = good_repos[batch:batch + batch_size]\n",
    "        batch_items = []    # Embeddings of the positive and negative samples\n",
    "        query_emb = []\n",
    "        batch_labels = []   # 1 for positive and -1 for negative samples\n",
    "        for (ind, ttl), paper in batch_papers:\n",
    "            q_emb = torch.Tensor(doc2vec_model.infer_vector(paper)).to(device)\n",
    "            for author in preprocessed_users[ind]:\n",
    "                if author not in mapping:\n",
    "                    continue\n",
    "                batch_items.append(emb[mapping[author]])\n",
    "                negs = []\n",
    "                while len(negs) < num_negative_samples:\n",
    "                    neg = sample(graph.nodes, 1)[0]\n",
    "                    while neg in preprocessed_users[ind] or neg not in mapping or neg in negs:\n",
    "                        neg = sample(graph.nodes, 1)[0]\n",
    "                    negs.append(neg)\n",
    "                for neg in negs:\n",
    "                    batch_items.append(emb[mapping[neg]])\n",
    "                batch_labels.extend([1] + ([-1] * num_negative_samples))\n",
    "                for i in range(num_negative_samples + 1):\n",
    "                    query_emb.append(q_emb)\n",
    "        query_emb = torch.stack(query_emb)\n",
    "        batch_items = torch.stack(batch_items)\n",
    "        batch_labels = torch.Tensor(batch_labels).to(device).detach()  \n",
    "        loss = criterion(query_emb, batch_items, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(total_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saving_dir = config['train']['model_saving_dir']\n",
    "model_saving_path = f\"{model_saving_dir}/Github_{model_name}.pt\"\n",
    "torch.save(model.state_dict(), model_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Link prediction model\n",
    "\n",
    "We use the GAE model from torch_geometric for Link Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GAE\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "link_prediction_model_params = config['link_prediction']['model_params']\n",
    "gae_model = GAE(LinkPredictionModel(*link_prediction_model_params))\n",
    "gae_optim = torch.optim.Adam(gae_model.parameters(), lr=1e-2)\n",
    "\n",
    "train_data, _, test_data = RandomLinkSplit(num_val=0,split_labels=True)(graph_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_prediction_epochs = config['link_prediction']['num_epochs']\n",
    "for _ in range(link_prediction_epochs):\n",
    "    gae_model.train()\n",
    "    gae_model.to(device)\n",
    "    gae_optim.zero_grad()\n",
    "    z = gae_model.encode(train_data.x.float().cuda(), train_data.edge_index.cuda())\n",
    "\n",
    "    loss = gae_model.recon_loss(z, pos_edge_index=train_data.pos_edge_label_index, neg_edge_index=train_data.neg_edge_label_index)\n",
    "    print(\"loss:\", loss.item(), end=\" \")\n",
    "    loss.backward()\n",
    "    gae_optim.step()\n",
    "    gae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        gae_model.eval()\n",
    "        z = gae_model.encode(test_data.x.float().cuda(), test_data.edge_index.cuda())\n",
    "        print(gae_model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Link Prediction model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_prediction_saving_dir = config['link_prediction']['model_saving_dir']\n",
    "link_prediction_saving_path = f\"{link_prediction_saving_dir}/Github_GAE.pt\"\n",
    "\n",
    "torch.save(gae_model.state_dict(), link_prediction_saving_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
